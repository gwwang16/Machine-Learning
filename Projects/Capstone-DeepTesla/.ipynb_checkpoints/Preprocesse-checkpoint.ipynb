{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customer Flow Forecasts on Koubei.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Background\n",
    "With the prevalent mobile location-based service, Alibaba and Ant Financial accumulate huge amount of user data on the platform every day, from brick and mortar store receipts to online shopping records. Koubei, Ant Financial’s online-to-offline platform utilizes the data to provide merchants with customized back-end business intelligence services, including transaction statistics, sales analysis and marketing recommendations. For example, Koubei aims to offer sales forecast services for every merchant on the platform. Basing on the forecasts, merchants can optimize their operations, reduce cost and improve user experience. \n",
    "\n",
    "Here, we present this challenge by properly reformulating the problem. We encourage innovative ideas to help achieve a more intelligent business platform which serves the business and the society better. We hope every participant enjoys the challenge.\n",
    "\n",
    "### Statement\n",
    "Forecasting customer flow is one of the key factors to a successful business. On Koubei platform, we define customer flow as “the number of customers making payment via Alipay in a shop during a particular period of time\". We provide customers’ browsing and payment history as well as the relevant information of shops. Participants are expected to predict the customer flow per day during the next 14 days for each shop.\n",
    "\n",
    "We strongly encourage participates to incorporate additional data like weather, etc., and share your data source with other participants on the forum.\n",
    "\n",
    "### Evaluation\n",
    "All submissions need to predict the customer flow per day (00:00:00 - 23:59:59) during the 14 days in the test set (11.01.2016-11.14.2016) for each shop. The results should be non-negative integers.\n",
    "The performance metric below is employed to measure the difference between the prediction and the truth:\n",
    "\n",
    "- $c_{it}:第t天，商家i的客户流量预测值$\n",
    "- $c_{it}^g:第t天，商家i的客户流量实际值$\n",
    "\n",
    "$$L = \\frac{1}{nT} \\sum_i^n\\sum_t^T \\left|\\frac{c_{it}-c_{it}^g}{c_{it}+c_{it}^g}\\right|$$\n",
    "\n",
    "### Data\n",
    "We provide shop information, Alipay users’ payment log and users’ browsing log from 07.01.2015 to 10.31.2016 (except 2015.12.12). All provided data are of string type, and participants’ prediction data should be of integer type. Data files are csv format without header row, with utf-8 encoding.\n",
    "\n",
    "1. shop_info：shop information data\n",
    "   \n",
    "|Field         |Sample    |Description |\n",
    "|:------------:|:--------:|:----------:|\n",
    "|shop_id       |000001    |商家id|\n",
    "|city_name     |  北京    |  市名|\n",
    "|location_id   |001       | 所在位置编号，位置接近的商家具有相同的编号|\n",
    "|per_pay       |3         |人均消费（数值越大消费越高）|\n",
    "|score         | 1        |评分（数值越大评分越高）|\n",
    "|comment_cnt   | 2        | 评论数（数值越大评论数越多）|\n",
    "|shop_level    | 1        | 门店等级（数值越大门店等级越高）|\n",
    "|cate_1_name   | 美食     |  一级品类名称|\n",
    "|cate_2_name   |小吃      | 二级分类名称|\n",
    "|cate_3_name   | 其他小吃 |三级分类名称|\n",
    "\n",
    "2. user_pay：users pay behavior\n",
    "\n",
    "|Field         |Sample  |Description|\n",
    "|:------------:|:------:|:---------:|\n",
    "|user_id       |0000000001|用户id|\n",
    "|shop_id       |000001  |商家id，与shop_info对应|\n",
    "|time_stamp    |2015-10-10 11:00:00|支付时间|\n",
    "\n",
    "3.  user_view：users view behavior\n",
    "\n",
    "|Field     |Sample    |Description |\n",
    "|:--------:|:--------:|:----------:|\n",
    "|user_id   |0000000001|用户id      |\n",
    "|shop_id   |000001    |商家id，与shop_info对应|\n",
    "|time_stamp|2015-10-10 10:00:00|浏览时间|\n",
    "\n",
    "4. prediction：test set and submission format\n",
    "\n",
    "|Field|Sample|Description|\n",
    "|:------------:|:------:|:----------:|\n",
    "|shop_id|000001|商家id|\n",
    "|day_1|25|第1天的预测值（ 需要选手提供）|\n",
    "|day_2|3|第2天的预测值（需要选手提供）|\n",
    "|……|||\n",
    "|day_14|1024|第14天的预测值（ 需要选手提供）|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "%matplotlib inline\n",
    "bases_dir = \"dataset\"\n",
    "new_dir = \"data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## shop_info "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shop_info = pd.read_csv(os.path.join(bases_dir, 'shop_info.txt'),header=None,\\\n",
    "                        names=['shop_id','city_name','location_id','per_pay',\\\n",
    "                               'score','comment_cnt','shop_level','cate_1_name',\\\n",
    "                               'cate_2_name','cate_3_name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill null cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "shop_id          0\n",
       "city_name        0\n",
       "location_id      0\n",
       "per_pay          0\n",
       "score          291\n",
       "comment_cnt    291\n",
       "shop_level       0\n",
       "cate_1_name      0\n",
       "cate_2_name      0\n",
       "cate_3_name    585\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shop_info.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "shop_id        1000.500000\n",
       "location_id     583.083000\n",
       "per_pay          10.479000\n",
       "score             2.677004\n",
       "comment_cnt       3.130486\n",
       "shop_level        0.814500\n",
       "dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shop_info.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The null cells of cate_3_name are filled with \"no_label\"\n",
    "- The null cells of score and comment_cnt are filled with there mean num."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#The mean of score and comment_cnt are 3.\n",
    "shop_info['score'] = shop_info['score'].fillna(3)\n",
    "shop_info['comment_cnt'] = shop_info['comment_cnt'].fillna(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shop_id</th>\n",
       "      <th>city_name</th>\n",
       "      <th>location_id</th>\n",
       "      <th>per_pay</th>\n",
       "      <th>score</th>\n",
       "      <th>comment_cnt</th>\n",
       "      <th>shop_level</th>\n",
       "      <th>cate_1_name</th>\n",
       "      <th>cate_2_name</th>\n",
       "      <th>cate_3_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>湖州</td>\n",
       "      <td>885</td>\n",
       "      <td>8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2</td>\n",
       "      <td>美食</td>\n",
       "      <td>休闲茶饮</td>\n",
       "      <td>饮品/甜点</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>哈尔滨</td>\n",
       "      <td>64</td>\n",
       "      <td>19</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>超市便利店</td>\n",
       "      <td>超市</td>\n",
       "      <td>no_label</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>南昌</td>\n",
       "      <td>774</td>\n",
       "      <td>5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>美食</td>\n",
       "      <td>休闲茶饮</td>\n",
       "      <td>奶茶</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>天津</td>\n",
       "      <td>380</td>\n",
       "      <td>18</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>超市便利店</td>\n",
       "      <td>超市</td>\n",
       "      <td>no_label</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>杭州</td>\n",
       "      <td>263</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>美食</td>\n",
       "      <td>休闲食品</td>\n",
       "      <td>生鲜水果</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   shop_id city_name  location_id  per_pay  score  comment_cnt  shop_level  \\\n",
       "0        1        湖州          885        8    4.0         12.0           2   \n",
       "1        2       哈尔滨           64       19    3.0          3.0           1   \n",
       "2        3        南昌          774        5    3.0          2.0           0   \n",
       "3        4        天津          380       18    3.0          3.0           1   \n",
       "4        5        杭州          263        2    2.0          2.0           0   \n",
       "\n",
       "  cate_1_name cate_2_name cate_3_name  \n",
       "0          美食        休闲茶饮       饮品/甜点  \n",
       "1       超市便利店          超市    no_label  \n",
       "2          美食        休闲茶饮          奶茶  \n",
       "3       超市便利店          超市    no_label  \n",
       "4          美食        休闲食品        生鲜水果  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shop_info['cate_3_name'] = shop_info['cate_3_name'].fillna('no_label')\n",
    "shop_info.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dummy variables\n",
    "\n",
    "For some categorical variables, we need to make binary dummy variables. \n",
    "\n",
    "get_dummies()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shop_id</th>\n",
       "      <th>per_pay</th>\n",
       "      <th>comment_cnt</th>\n",
       "      <th>score_0.0</th>\n",
       "      <th>score_1.0</th>\n",
       "      <th>score_2.0</th>\n",
       "      <th>score_3.0</th>\n",
       "      <th>score_4.0</th>\n",
       "      <th>shop_level_0</th>\n",
       "      <th>shop_level_1</th>\n",
       "      <th>...</th>\n",
       "      <th>cate_3_name_西北菜</th>\n",
       "      <th>cate_3_name_西式快餐</th>\n",
       "      <th>cate_3_name_西餐</th>\n",
       "      <th>cate_3_name_闽菜</th>\n",
       "      <th>cate_3_name_零食</th>\n",
       "      <th>cate_3_name_面包</th>\n",
       "      <th>cate_3_name_面点</th>\n",
       "      <th>cate_3_name_饮品/甜点</th>\n",
       "      <th>cate_3_name_香锅/烤鱼</th>\n",
       "      <th>cate_3_name_麻辣烫/串串香</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 78 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   shop_id  per_pay  comment_cnt  score_0.0  score_1.0  score_2.0  score_3.0  \\\n",
       "0        1        8         12.0          0          0          0          0   \n",
       "1        2       19          3.0          0          0          0          1   \n",
       "2        3        5          2.0          0          0          0          1   \n",
       "3        4       18          3.0          0          0          0          1   \n",
       "4        5        2          2.0          0          0          1          0   \n",
       "\n",
       "   score_4.0  shop_level_0  shop_level_1         ...           \\\n",
       "0          1             0             0         ...            \n",
       "1          0             0             1         ...            \n",
       "2          0             1             0         ...            \n",
       "3          0             0             1         ...            \n",
       "4          0             1             0         ...            \n",
       "\n",
       "   cate_3_name_西北菜  cate_3_name_西式快餐  cate_3_name_西餐  cate_3_name_闽菜  \\\n",
       "0                0                 0               0               0   \n",
       "1                0                 0               0               0   \n",
       "2                0                 0               0               0   \n",
       "3                0                 0               0               0   \n",
       "4                0                 0               0               0   \n",
       "\n",
       "   cate_3_name_零食  cate_3_name_面包  cate_3_name_面点  cate_3_name_饮品/甜点  \\\n",
       "0               0               0               0                  1   \n",
       "1               0               0               0                  0   \n",
       "2               0               0               0                  0   \n",
       "3               0               0               0                  0   \n",
       "4               0               0               0                  0   \n",
       "\n",
       "   cate_3_name_香锅/烤鱼  cate_3_name_麻辣烫/串串香  \n",
       "0                  0                    0  \n",
       "1                  0                    0  \n",
       "2                  0                    0  \n",
       "3                  0                    0  \n",
       "4                  0                    0  \n",
       "\n",
       "[5 rows x 78 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_fields = ['score','shop_level','cate_1_name', 'cate_2_name','cate_3_name']\n",
    "for each in dummy_fields:\n",
    "    dummies = pd.get_dummies(shop_info[each], prefix=each, drop_first=False)\n",
    "    shop_info = pd.concat([shop_info, dummies], axis=1)\n",
    "\n",
    "# drop some nonusefull features.\n",
    "fields_to_drop = ['city_name','location_id','score',\\\n",
    "                  'shop_level','cate_1_name', 'cate_2_name','cate_3_name']\n",
    "shop_info_data = shop_info.drop(fields_to_drop, axis=1)\n",
    "\n",
    "shop_info_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del dummy_fields\n",
    "del fields_to_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save shop_info data\n",
    "shop_info_data.to_csv(os.path.join(new_dir, 'shop_info.csv'),\\\n",
    "                 index=False,encoding=\"utf-8\")\n",
    "del shop_info_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## user_view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_view = pd.read_csv(os.path.join(bases_dir, 'user_view.txt'),header=None,\\\n",
    "                       names=['user_id','shop_id','time_stamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# time_stamp to date-time format\n",
    "time_slice = pd.to_datetime(user_view.time_stamp)\n",
    "user_view[\"week\"] = time_slice.map(lambda x: x.isoweekday()) # add week\n",
    "user_view[\"date\"] = pd.DatetimeIndex(user_view['time_stamp']).date\n",
    "user_view[\"time\"] = pd.DatetimeIndex(user_view['time_stamp']).hour\n",
    "# user_view[\"time\"]=pd.DatetimeIndex(user_view['time_stamp']).hour # another method\n",
    "del time_slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# drop useless column\n",
    "user_view = user_view.drop('time_stamp', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# count user view num in each hour\n",
    "temp = user_view.groupby(['shop_id','date','week','time']).count()\n",
    "temp_df = temp.reset_index(level=['shop_id','date','week','time'])\n",
    "\n",
    "# rename use_id to view_num\n",
    "temp_df.rename(columns={temp_df.columns[4]:'view_num'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save user_view file\n",
    "temp_df.to_csv(os.path.join(new_dir, 'user_view.csv'), \\\n",
    "               index=False, header=True)\n",
    "\n",
    "del temp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## user_pay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_pay = pd.read_csv(os.path.join(bases_dir, 'user_pay.txt'),header=None,\\\n",
    "                      names=['user_id','shop_id','time_stamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "time_slice = pd.to_datetime(user_pay.time_stamp)\n",
    "\n",
    "user_pay[\"week\"] = time_slice.map(lambda x: x.isoweekday()) # add week\n",
    "user_pay[\"date\"] = pd.DatetimeIndex(user_pay['time_stamp']).date\n",
    "#user_pay[\"time\"] = pd.DatetimeIndex(user_pay['time_stamp']).hour\n",
    "# user_view[\"time\"]= # another method\n",
    "del time_slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_pay['date'] = pd.to_datetime(user_pay['date'])\n",
    "user_pay = user_pay.drop(\"time_stamp\", axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "user_pay.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_pay_df = user_pay.groupby(['shop_id','date','week']).count().reset_index(level=['shop_id','date','week'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "user_pay_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_pay_df.rename(columns={user_pay_df.columns[3]:'pay_num'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save user_pay data\n",
    "user_pay_df.to_csv(os.path.join(new_dir, 'user_pay_p1.csv'), \\\n",
    "                index=False, header=True)\n",
    "del user_pay_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_pay_df = pd.read_csv(os.path.join(new_dir,'user_pay_p1.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dummy_fields = ['week']\n",
    "for each in dummy_fields:\n",
    "    dummies = pd.get_dummies(user_pay_df[each], prefix=each, drop_first=False)\n",
    "    user_pay_df = pd.concat([user_pay_df, dummies], axis=1)\n",
    "\n",
    "# drop some nonusefull features.\n",
    "fields_to_drop = ['week']\n",
    "user_pay_data = user_pay_df.drop(fields_to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "user_pay_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del dummy_fields\n",
    "del fields_to_drop\n",
    "del user_pay_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save user_pay data\n",
    "user_pay_data.to_csv(os.path.join(new_dir, 'user_pay.csv'), \\\n",
    "                index=False, header=True)\n",
    "del user_pay_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## holiday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "holiday_info = pd.read_csv(os.path.join(bases_dir, 'holiday.csv'),header=None,\\\n",
    "                       names=['time_stamp','holiday'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "holiday_info[\"date\"] = pd.DatetimeIndex(holiday_info['time_stamp']).date\n",
    "holiday_info = holiday_info.drop(['time_stamp'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "holiday_info['date'] = pd.to_datetime(holiday_info['date'])\n",
    "holiday_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save holiday data\n",
    "holiday_info.to_csv(os.path.join(new_dir, 'holiday_info.csv'), \\\n",
    "                    index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "shop_info = pd.read_csv(os.path.join(new_dir,'shop_info.csv'),encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "user_view = pd.read_csv(os.path.join(new_dir,'user_view.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "user_pay = pd.read_csv(os.path.join(new_dir,'user_pay.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "holiday_info = pd.read_csv(os.path.join(new_dir,'holiday_info.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "view_data = pd.merge(user_view,shop_info,on=['shop_id'],how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "shop_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "holiday_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del dummy_fields\n",
    "del fields_to_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "user_pay.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "full_data = pd.merge(user_pay,shop_info,on=['shop_id'],how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full_data = pd.merge(full_data,holiday_info,on=['date'],how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "full_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "full_data[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# holiday data are missing from 2015-6-26 to 2015-6-30\n",
    "# fill 0\n",
    "full_data['holiday'] = full_data['holiday'].fillna(0)\n",
    "\n",
    "# holiday data 1:weekend,2:holiday\n",
    "# select holiday only to avoid duplication with week\n",
    "full_data['holiday'] = (full_data['holiday'] >1).astype(int) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full_data.to_csv(os.path.join(new_dir, 'full_data.csv'),\\\n",
    "                 index=False,encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "view_data.to_csv(os.path.join(new_dir, 'view_data.csv'),\\\n",
    "                 index=False,encoding=\"utf-8\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
