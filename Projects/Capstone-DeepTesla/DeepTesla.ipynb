{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Engineer Nanodegree\n",
    "## Capstone Project : DeepTesla\n",
    "Guangwei Wang  \n",
    "March 20st, 2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition\n",
    "### Project Overview\n",
    "\n",
    "This project is based on Course [MIT 6.S094: Deep Learning for Self-Driving Cars](http://selfdrivingcars.mit.edu/deeptesl/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem Statement\n",
    "\n",
    "This project is an end-to-end learning problem. The goal is to predict the steering wheel angel from Tesla dataset based on the video of the forward roadway."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets and Inputs\n",
    "\n",
    "Databases with real-traffic video data captured and extracted 10 video clips of highway driving from Tesla:\n",
    "\n",
    "- The wheel value was extracted from the in-vehicle CAN\n",
    "\n",
    "- A window from each video frame is cropped/extracted and provide a CSV linking the window to a wheel value.\n",
    "\n",
    "A snapshot of video frame:\n",
    "<img src=\"./images/img/frame_1173.jpg\" width = \"320\" height = \"180\" align=center />\n",
    "    \n",
    "The CSV data format:\n",
    "\n",
    "\n",
    "|  ts_micro         | frame_index | wheel |\n",
    "|:-----------------:|:-----------:|:-----:|\n",
    "|  1464305394391807 | 0           | -0.5  |\n",
    "| 1464305394425141  | 1           | -0.5  | \n",
    "| 1464305394458474  | 2           | -0.5  |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Metrics\n",
    "\n",
    "This is a regression problem, MSE metrics is adopted here.\n",
    "\n",
    "$$MSE = \\frac{1}{N} \\sum_{N}^{i=1}\\sqrt{y_{p} - y}$$\n",
    "where, $y_p$ is the predicted steering wheel angle, $y$ denotes the reference steering wheel angle, and the sample number is `N`. The lower MSE is preferred.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm\n",
    "import os\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import local env\n",
    "import params\n",
    "import helper\n",
    "import preprocess\n",
    "\n",
    "data_dir = params.data_dir\n",
    "out_dir = params.out_dir\n",
    "model_dir = params.model_dir\n",
    "\n",
    "img_height = params.img_height\n",
    "img_width = params.img_width\n",
    "img_channels = params.img_channels\n",
    "batch_size = params.batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steering angle info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "csv_files = glob.glob(os.path.join(data_dir, \"*steering.csv\"))\n",
    "steering_csv = pd.concat((pd.read_csv(f) for f in csv_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "steering_csv[-3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "steering_csv.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "steering_csv.wheel.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wheel = steering_csv['wheel']\n",
    "plt.figure\n",
    "plt.hist(wheel,50);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.image as mpimg\n",
    "img=mpimg.imread(\"images/img/frame_1173.jpg\")\n",
    "imgplot = plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img = preprocess.preprocess(img)\n",
    "imgplot = plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(\"epochs/epoch03_front.mkv\")\n",
    "length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "width  = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps    = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "print (length,width,height,fps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The frame count of video is large than csv 2 frame counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Merge all frames together with corresponding steering wheel angle.\n",
    "- Show one frame of the preprocessed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imgs_wheels_train = preprocess.load_data('train')\n",
    "helper.display_states(imgs_wheels_train,100)\n",
    "\n",
    "# shuffle dataframe rows\n",
    "imgs_wheels_train = imgs_wheels_train.sample(frac=1).reset_index(drop=True)\n",
    "# Normalize\n",
    "imgs_wheels_train.imgs = imgs_wheels_train.imgs / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imgs_wheels_val = preprocess.load_data('valid')\n",
    "helper.display_states(imgs_wheels_val,100)\n",
    "\n",
    "# shuffle dataframe rows\n",
    "imgs_wheels_val = imgs_wheels_val.sample(frac=1).reset_index(drop=True)\n",
    "# Normalize\n",
    "imgs_wheels_val.imgs = imgs_wheels_val.imgs / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imgs_wheels_train.imgs[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24300, 66, 200, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(imgs_train).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1c2801d3fd0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAuUAAAEgCAYAAAAT9w1kAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c2e3c33240>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 144,
       "width": 370
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "imgs_train, wheels_train = preprocess.load_data_v2('train')\n",
    "plt.imshow(imgs_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imgs_val, wheels_val = preprocess.load_data_v2 ('valid')\n",
    "plt.imshow(imgs_val[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To do. Save the check point data\n",
    "# pikle has memory error, hasn't solved"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check point\n",
    "\n",
    "The data has been processed by\n",
    "- Merge data together\n",
    "- Shuffle\n",
    "- Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution and Max Pooling Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def conv2d(x_tensor, conv_num_outputs, conv_ksize, conv_strides):\n",
    "    \"\"\"\n",
    "    Apply convolution to x_tensor\n",
    "    :param x_tensor: TensorFlow Tensor\n",
    "    :param conv_num_outputs: Number of outputs for the convolutional layer\n",
    "    :param conv_strides: Stride 2-D Tuple for convolution\n",
    "    :return: A tensor that represents convolution of x_tensor\n",
    "    \"\"\"\n",
    "    _,_,_,input_depth = x_tensor.get_shape()\n",
    "    weight = tf.Variable(tf.truncated_normal((*conv_ksize,int(input_depth),conv_num_outputs),\n",
    "                                             mean=0.0, stddev=0.1), name='weight')\n",
    "    bias = tf.Variable(tf.truncated_normal([conv_num_outputs]), name='bias')\n",
    "    \n",
    "    # Apply a convolution, add bias, and add nonlinear activation\n",
    "    x_tensor = tf.nn.conv2d(x_tensor, \n",
    "                            weight, \n",
    "                            strides = [1,*conv_strides,1], \n",
    "                            padding = 'SAME')\n",
    "    x_tensor = tf.nn.bias_add(x_tensor, bias)\n",
    "    return tf.nn.relu(x_tensor)\n",
    "\n",
    "def max_pool(x_tensor, pool_ksize, pool_strides):\n",
    "    \"\"\"\n",
    "    Apply max pooling to x_tensor\n",
    "    :param x_tensor: TensorFlow Tensor\n",
    "    :param pool_ksize: kernal size 2-D Tuple for pool\n",
    "    :param pool_strides: Stride 2-D Tuple for pool\n",
    "    :return: A tensor that represents max pooling of x_tensor\n",
    "    \"\"\"\n",
    "    return tf.nn.max_pool(x_tensor, \n",
    "                          ksize = [1,*pool_ksize,1], \n",
    "                          strides = [1,*pool_strides,1], \n",
    "                          padding = 'SAME')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flatten Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def flatten(x_tensor):\n",
    "    \"\"\"\n",
    "    Flatten x_tensor to (Batch Size, Flattened Image Size)\n",
    "    : x_tensor: A tensor of size (Batch Size, ...), where ... are the image dimensions.\n",
    "    : return: A tensor of size (Batch Size, Flattened Image Size).\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    # If one component of shape is the special value -1, \n",
    "    # the size of that dimension is computed so that the total size remains constant.\n",
    "    _, size_x, size_y, depth = x_tensor.get_shape()\n",
    "    return tf.reshape(x_tensor, [-1, int(size_x)*int(size_y)*int(depth)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully-Connected Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fully_conn(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a fully connected layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    weight = tf.Variable(tf.truncated_normal((int(x_tensor.get_shape()[1]),num_outputs),\n",
    "                                             mean=0.0, stddev=0.05))\n",
    "    bias = tf.Variable(tf.truncated_normal([num_outputs]))\n",
    "    y = tf.nn.bias_add(tf.matmul(x_tensor, weight), bias)\n",
    "    return tf.nn.relu(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def output(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a output layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    weight = tf.Variable(tf.truncated_normal((int(x_tensor.get_shape()[1]),num_outputs),\n",
    "                                             mean=0.0, stddev=0.05))\n",
    "    bias = tf.Variable(tf.truncated_normal([num_outputs]))\n",
    "    return tf.nn.bias_add(tf.matmul(x_tensor, weight), bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv_net(x, keep_prob):\n",
    "    \"\"\"\n",
    "    Create a convolutional neural network model\n",
    "    : x: Placeholder tensor that holds image data.\n",
    "    : keep_prob: Placeholder tensor that hold dropout keep probability.\n",
    "    : return: Tensor that represents logits\n",
    "    \"\"\"\n",
    "    conv_1 = conv2d(x_tensor=x,\n",
    "                           conv_num_outputs=24,\n",
    "                           conv_ksize=[3,3],\n",
    "                           conv_strides=[1,1])\n",
    "    conv_1 = max_pool(x_tensor = conv_1,\n",
    "                      pool_ksize=[3,3],\n",
    "                      pool_strides=[2,2])\n",
    "    \n",
    "    conv_2 = conv2d(x_tensor=conv_1,\n",
    "                    conv_num_outputs=36,\n",
    "                    conv_ksize=[3,3],\n",
    "                    conv_strides=[1,1])\n",
    "    conv_2 = max_pool(x_tensor = conv_2,\n",
    "                     pool_ksize=[3,3],\n",
    "                     pool_strides=[2,2])\n",
    "    \n",
    "    conv_3 = conv2d(x_tensor=conv_2,\n",
    "                    conv_num_outputs=48,\n",
    "                    conv_ksize=[3,3],\n",
    "                    conv_strides=[1,1])\n",
    "    conv_3 = max_pool(x_tensor = conv_3,\n",
    "                     pool_ksize=[3,3],\n",
    "                     pool_strides=[2,2])\n",
    "    \n",
    "    conv_4 = conv2d(x_tensor=conv_3,\n",
    "                    conv_num_outputs=64,\n",
    "                    conv_ksize=[3,3],\n",
    "                    conv_strides=[1,1])\n",
    "    conv_4 = max_pool(x_tensor = conv_4,\n",
    "                     pool_ksize=[3,3],\n",
    "                     pool_strides=[2,2])\n",
    "    \n",
    "    \n",
    "    fc0 = flatten(conv_4)\n",
    "    \n",
    "    fc1 = fully_conn(fc0, 256)     \n",
    "    fc1 = tf.nn.dropout(fc1, keep_prob)\n",
    "    \n",
    "    fc2 = fully_conn(fc1, 256)     \n",
    "    fc2 = tf.nn.dropout(fc2, keep_prob)\n",
    "    \n",
    "    out = output(fc2, 1)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "# Inputs\n",
    "x = tf.placeholder(tf.float32,\n",
    "                   [None, params.img_height, params.img_width, params.img_channels], \n",
    "                   name='x')\n",
    "y_ = tf.placeholder(tf.float32, [None, 1], name='y_')\n",
    "keep_prob = tf.placeholder(tf.float32, name='keep_prob')\n",
    "\n",
    "\n",
    "# Model\n",
    "y = conv_net(x, keep_prob)\n",
    "y = tf.identity(y, name='y')\n",
    "\n",
    "# Lost and Optimizer\n",
    "loss = tf.reduce_mean(tf.square(tf.sub(y_, y)))\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(loss)\n",
    "\n",
    "# Accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "batch_size = 128\n",
    "keep_probability = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.array(imgs_train).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "txx, tyy = helper.load_batch_v2(imgs_train, wheels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.array(txx).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "this_x = np.reshape(tyy,(batch_size,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "this_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(imgs_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking the Training on a Single Batch...\n",
      "step 1 of 100, train loss 134.361083984375, val loss 25.994142532348633\n",
      "step 2 of 100, train loss 1245.10693359375, val loss 1982.8524169921875\n",
      "step 3 of 100, train loss 2625.88720703125, val loss 4184.75537109375\n",
      "step 4 of 100, train loss 2633.14453125, val loss 3898.025146484375\n",
      "step 5 of 100, train loss 1914.427001953125, val loss 2626.14111328125\n",
      "step 6 of 100, train loss 964.5149536132812, val loss 1375.9837646484375\n",
      "step 7 of 100, train loss 329.2017822265625, val loss 532.021484375\n",
      "step 8 of 100, train loss 100.12478637695312, val loss 135.6635284423828\n",
      "step 9 of 100, train loss 48.59143829345703, val loss 15.032796859741211\n",
      "step 10 of 100, train loss 67.41447448730469, val loss 27.969968795776367\n",
      "step 11 of 100, train loss 122.10951232910156, val loss 56.45073318481445\n",
      "step 12 of 100, train loss 109.32460021972656, val loss 64.35442352294922\n",
      "step 13 of 100, train loss 118.40594482421875, val loss 51.16001510620117\n",
      "step 14 of 100, train loss 66.85567474365234, val loss 24.63562774658203\n",
      "step 15 of 100, train loss 54.20318603515625, val loss 7.2134785652160645\n",
      "step 16 of 100, train loss 38.839839935302734, val loss 10.523590087890625\n",
      "step 17 of 100, train loss 53.11381530761719, val loss 32.06779861450195\n",
      "step 18 of 100, train loss 62.157752990722656, val loss 61.5921630859375\n",
      "step 19 of 100, train loss 75.34658813476562, val loss 89.5831527709961\n",
      "step 20 of 100, train loss 105.00809478759766, val loss 105.22904968261719\n",
      "step 21 of 100, train loss 104.20159149169922, val loss 109.268310546875\n",
      "step 22 of 100, train loss 111.90544128417969, val loss 107.17005920410156\n",
      "step 23 of 100, train loss 106.23389434814453, val loss 97.72757720947266\n",
      "step 24 of 100, train loss 105.60986328125, val loss 83.678955078125\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-6ebd33a6d61a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0mvyy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvyy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvyy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[0mt_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtxx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtyy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeep_prob\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m         \u001b[0mv_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mvxx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mvyy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeep_prob\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m         \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"step {} of {}, train loss {}, val loss {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files\\envs\\tflearn\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36meval\u001b[1;34m(self, feed_dict, session)\u001b[0m\n\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \"\"\"\n\u001b[1;32m--> 575\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_eval_using_default_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    576\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    577\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files\\envs\\tflearn\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_eval_using_default_session\u001b[1;34m(tensors, feed_dict, graph, session)\u001b[0m\n\u001b[0;32m   3631\u001b[0m                        \u001b[1;34m\"the tensor's graph is different from the session's \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3632\u001b[0m                        \"graph.\")\n\u001b[1;32m-> 3633\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3634\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3635\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files\\envs\\tflearn\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    764\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    765\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 766\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    767\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    768\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files\\envs\\tflearn\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    962\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    963\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m--> 964\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    965\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    966\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files\\envs\\tflearn\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1012\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1013\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m-> 1014\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m   1015\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1016\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32mD:\\Program Files\\envs\\tflearn\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1019\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1020\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1021\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1022\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1023\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files\\envs\\tflearn\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1001\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[0;32m   1002\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1003\u001b[1;33m                                  status, run_metadata)\n\u001b[0m\u001b[0;32m   1004\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1005\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# v2\n",
    "print('Checking the Training on a Single Batch...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        txx, tyy = helper.load_batch_v2(imgs_train[:-2000], wheels_train[:-2000])\n",
    "        tyy = np.reshape(tyy,(batch_size,1))\n",
    "        train_step.run(feed_dict={x: txx, y_: tyy, keep_prob: keep_probability})\n",
    "        \n",
    "        \n",
    "        #for batch_features, batch_targetss in txx, tyy:\n",
    "        #    train_neural_network(sess, optimizer, keep_probability, batch_features, batch_targets)\n",
    "        #if (i+1) % 10 == 0:\n",
    "        #vxx, vyy = imgs_val, wheels_val\n",
    "        #if (epoch+1) % 10 == 0:\n",
    "        vxx, vyy = imgs_train[-2000:], wheels_train[-2000:]\n",
    "        vyy = np.reshape(vyy,(len(vyy),1))\n",
    "        t_loss = loss.eval(feed_dict={x: txx, y_: tyy, keep_prob: 1.0})\n",
    "        v_loss = loss.eval(feed_dict={x: vxx, y_: vyy, keep_prob: 1.0})\n",
    "        print (\"step {} of {}, train loss {}, val loss {}\".format(epoch+1, epochs, t_loss, v_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "loss = tf.reduce_mean(tf.square(tf.sub(y_, y)))\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(loss)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "time_start = time.time()\n",
    "\n",
    "\n",
    "for i in range(training_steps):\n",
    "    txx, tyy = imgs_wheels_train.imgs,imgs_wheels_train.wheels\n",
    "        \n",
    "    train_step.run(feed_dict={x: txx, y_: tyy, keep_prob: 0.8})\n",
    "\n",
    "\n",
    "\n",
    "    if (i+1) % 10 == 0:\n",
    "        vxx, vyy = imgs_wheels_val.imgs,imgs_wheels_val.wheels\n",
    "        t_loss = loss.eval(feed_dict={x: txx, y_: tyy, keep_prob: 1.0})\n",
    "        v_loss = loss.eval(feed_dict={x: vxx, y_: vyy, keep_prob: 1.0})\n",
    "        print ('step {} of {}, train loss {}, val loss {:2f}'\n",
    "               .format(i+1, training_steps, t_loss, v_loss))\n",
    "\n",
    "    if (i+1) % 100 == 0:\n",
    "        if not os.path.exists(params.save_dir):\n",
    "            os.makedirs(params.save_dir)\n",
    "        checkpoint_path = os.path.join(params.save_dir, \"model.ckpt\")\n",
    "        filename = saver.save(sess, checkpoint_path)\n",
    "\n",
    "        time_passed = cm.pretty_running_time(time_start)\n",
    "        time_left = cm.pretty_time_left(time_start, i, params.training_steps)\n",
    "        print ('Model saved. Time passed: {}. Time left: {:2f}'.format(time_passed, time_left))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_batch(dataframe, batch_size, batch_i):\n",
    "    #imgs = dataframe['imgs']\n",
    "    #wheels = dataframe['wheels']\n",
    "    #n = len(imgs)\n",
    "\n",
    "    #batch_count = int(np.ceil(frame_count / batch_size))\n",
    "    #for batch in range(batch_count):\n",
    "    df = pd.DataFrame()\n",
    "    frame_start = batch_i * batch_size\n",
    "    frame_end = frame_start + batch_size\n",
    "    df = dataframe[frame_start:frame_end]\n",
    "   \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "epoch_id = 1\n",
    "epoch_id = 1\n",
    "helper.display_states(epoch_id,frame_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import helper\n",
    "epochs_train = [3, 4, 5, 6, 8]\n",
    "#epochs_val = [1, 2, 7, 9]\n",
    "\n",
    "epochs_val = [1, 2]\n",
    "\n",
    "\n",
    "def load_data(mode):\n",
    "    '''get train or valid batch data\n",
    "    mode: train or valid\n",
    "    output: batch data'''\n",
    "    if mode == 'train':\n",
    "        epochs = [3, 4, 5, 6, 8]\n",
    "    elif mode == 'valid':\n",
    "        epochs = [1, 2, 7, 9]\n",
    "    else:\n",
    "        print('wrong mode inpu')\n",
    "        \n",
    "    batches = pd.DataFrame()\n",
    "\n",
    "    for epoch_id in epochs: \n",
    "        vid_path = os.path.join(data_dir, 'epoch{:0>2}_front.mkv'.format(epoch_id))\n",
    "        frame_count = helper.frame_count(vid_path)\n",
    "        batch_count = int(np.ceil(frame_count / batch_size))\n",
    "    \n",
    "        for batch in range(batch_count):\n",
    "            df = pd.DataFrame()\n",
    "            batch += 1\n",
    "            frame_start = batch * batch_size\n",
    "            frame_end = frame_start + batch_size\n",
    "            df = pd.DataFrame({'epoch_id':[epoch_id],'frame_start':[frame_start],'frame_end':[frame_end]})\n",
    "            batches = pd.concat([batches,df], axis=0)\n",
    "    return batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "current_batch_id = 1\n",
    "\n",
    "def load_batch(batches):\n",
    "    global current_batch_id\n",
    "    xx = []\n",
    "    yy = []\n",
    "\n",
    "    # acquire the batch info\n",
    "    batch_id = current_batch_id\n",
    "    batch = batches.iloc[batch_id]\n",
    "    epoch_id, frame_start, frame_end = batch.epoch_id, batch.frame_start, batch.frame_end\n",
    "\n",
    "    # update the current batch\n",
    "    current_batch_id = (current_batch_id + 1) % len(batches)\n",
    "\n",
    "    # extract image and steering data\n",
    "    vid_path = os.path.join(data_dir, 'epoch{:0>2}_front.mkv'.format(epoch_id))\n",
    "    frame_count = helper.frame_count(vid_path)\n",
    "    cap = cv2.VideoCapture(vid_path)\n",
    "    helper.cv2_goto_frame(cap, frame_start) \n",
    "    \n",
    "    csv_path = os.path.join(data_dir, 'epoch{:0>2}_steering.csv'.format(epoch_id))\n",
    "    \n",
    "    rows = pd.read_csv(csv_path)\n",
    "    yy = rows[frame_start:frame_end+1]['wheel'].values\n",
    "    \n",
    "    for frame_id in range(frame_start, frame_end+1):\n",
    "        _, img = cap.read()\n",
    "        img = preprocess(img)\n",
    "        xx.append(img)\n",
    "\n",
    "    assert len(xx) == len(yy)\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "    return xx, yy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batches = get_batch('valid')\n",
    "xx,yy = load_batch(batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = np.array(xx)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "yy.shape"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
